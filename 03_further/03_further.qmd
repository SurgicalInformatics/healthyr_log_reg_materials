---
title: "Model building in action"
author: "HealthyR+: Practical Logistic Regression, Session 3"
date: today
execute:
  warning: false
format:
  pdf: default
  html:
    code-fold: true
editor: visual
---

Restart your session! If that doesn't clear your environment, refer back to the instructions from the top of the last session or ask a tutor.

```{r}
#| message: false
#| warning: false

library(tidyverse)
library(broom)
library(finalfit)
theme_set(theme_bw())

heart_data = wcgs

# derived variables from previous session
heart_data = heart_data %>%
  mutate(years = (timechd/365) %>% 
           ff_label("Time (years)"),
         # CHD status at 8 years:
         chd_8yr = case_when(years >= 8 ~ "No" ,
                              years < 8 & chd == "Yes"  ~ "Yes",
                              years < 8 & chd == "No" ~ "Censored",
                              .default = "Other"
                            ) %>% 
           na_if("Censored") %>% 
           factor() %>% 
           ff_label("8-yr CHD"))
```

# *Variable selection*

*Based on what we learned about our variables in the previous session we can start building our final model. We know that:*

-   *our incomplete observations are not different to the rest of the dataset.*
-   *our continuous variables (age, cholesterole) have a monotonous response to 8-year coronary heart disease (only goes in one direction).*
-   *our continuous variables are independent of each other, and independent of the categorical variables in our dataset.*
-   *we know which categorical variables are related to each other: smoking and personality - although this is a weak relationship.*

# *Model Fitting*

*Three things are important to keep looking at:*

-   *what is the association between a particular variable and the outcome (OR and 95% CI);*

-   *how much information is a variable bringing to the model, e.g., change in AIC (lower better) and c-statistic (higher better).*

-   *how much influence does adding a variable have on the effect size of another variable, and in particular my variable of interest (a rule of thumb is seeing a greater than 10% change in the OR of the variable of interest when a new variable is added to the model, suggests the new variable is important).*

## *Multivariable model fitting 1 - start simple*

*Script set-up and most basic logistic regression model (fit1 from Session 2)*

```{r}
fit1_chd = heart_data %>% 
  finalfit("chd_8yr", "personality_2L", metrics = TRUE)

fit1     = fit1_chd[[1]]
met_fit1 = fit1_chd[[2]]
rm(fit1_chd) # good idea to remove this to reduce typos when copying

```

## *Multivariable model fitting 2 - maximal model*

*Create the variables `fit2_chd`, `fit2` (first element of `finalfit(..., metrics = TRUE)`) and `met_fit2` using all of the variables from the end of Session 1.*

```{r}
dependent   = "chd_8yr"
explanatory = c("personality_2L","age", "height", "weight",
                "sbp", "chol", "smoking", "arcus")

fit2_chd = heart_data %>% 
  finalfit(dependent, explanatory, metrics = TRUE)

fit2     = fit2_chd[[1]]
met_fit2 = fit2_chd[[2]]
rm(fit2_chd)
```

*Look at the `met_` variables in your Environment tab: better already, isn't it!*

## *Multivariable model fitting 3 - is `Smoking` a mediator?*

*A mediator is a variable that that lies on the causal pathway between the exposure and the outcome of interest.*

```{r}
# Fit 3
dependent   = "chd_8yr"
explanatory = c("personality_2L","age", "height", "weight",
                "sbp", "chol",
                #"smoking",
                "arcus")

fit3_chd = heart_data %>% 
  finalfit(dependent, explanatory, metrics = TRUE)

fit3     = fit3_chd[[1]]
met_fit3 = fit3_chd[[2]]
rm(fit3_chd)


# Does smoking predict personality?

heart_data %>% 
  finalfit("personality_2L", "smoking", metrics = TRUE)
```

## *Multivariable model fitting 4 - omit `systolic blood pressure`*

### *Exercise 1*

*Copy the above code and create a `fit4` where we further leave out `sbp` from the explanatory variable list*

```{r}
# Your R code here... 

# Fit 4


```

Looks like it is adding information after all. What if we omit weight?

## *Multivariable model fitting 5*

### *Categorising a continuous variable*

*The effect of systolic blood pressure may not be linear - check back to the plots we made in Session 2. Let's cut it into three categories.*

```{r}
heart_data  = heart_data %>% 
  mutate(sbp.2groups = if_else(sbp <= 120, "Normal", "High") %>% 
           factor() %>% 
           fct_relevel("Normal") %>% 
           ff_label("Systolic blood pressure")
         )

heart_data %>% 
  count(sbp.2groups)

dependent   = "chd_8yr"
explanatory = c("personality_2L","age", "height", "weight",
                "sbp.2groups",
                "chol",
                "smoking",
                "arcus")

fit5_chd = heart_data %>% 
  finalfit(dependent, explanatory, metrics = TRUE)

fit5      = fit5_chd[[1]]
met_fit5  = fit5_chd[[2]]
rm(fit5_chd)

```

## *Model so far*

*Note `explanatory.multi` syntax to include to specify multivariable model variables included in the OR (multivariable full) column output. Explanatory multi is a useful tool for assessing whether to retain variables in a model.*

```{r}
dependent   = "chd_8yr"
explanatory = c("personality_2L",
                "age",
                "height",
                "weight",
                "sbp.2groups",
                "chol",
                "smoking",
                "arcus")


explanatory.multi = c("personality_2L",
                "age",
                #"height",
                "weight",
                "sbp.2groups",
                "chol",
                "smoking" #,
                #"arcus"
                )

fit6_chd = heart_data %>% 
  finalfit(dependent, explanatory, explanatory.multi, metrics = TRUE, keep_models = TRUE)

fit6     = fit6_chd[[1]]
met_fit6 = fit6_chd[[2]]
rm(fit6_mchd)

```

# *Interactions*

*When an interaction exists between two explanatory variables, say **personality type** and **age**, it implies that the size of the personality effect on CHD, differs by blood pressure. Up until now, the model as assumed that the effect of personality on CHD is the same whether normal or high blood pressure.*

*But it might be reasonable to hypothesise that having high blood pressure is more harmful when you also have a type A personality.*

*We can add an interaction term to the model thus:*

```{r}
dependent   = "chd_8yr"
explanatory = c("personality_2L*sbp.2groups",
                "age",
                "height",
                "weight",
                #"sbp.2groups",
                "chol",
                "smoking",
                "arcus")

fit7_chd = heart_data %>% 
  finalfit(dependent, explanatory, metrics = TRUE)

fit7     = fit7_chd[[1]]
met_fit7 = fit7_chd[[2]]
rm(fit7_chd)

```

*The exponentiated coefficient for the interaction is a ratio. It can be interpreted as the factor by which the odds ratio of the personality changes when moving from the first level of the interaction variable (Normal) to the next (High).*

## *Interaction plots and prediction (advanced)*

*We can plot the response for the interaction to understand the interaction. This involved using `augment` which is considered advanced. A deep understanding of this is not required to complete the course.*

```{r}
#| fig-width: 5
#| fig-height: 3


# Produce interaction plots by predicting from the fitted model. 

# Create a set of patient characteristics by which to predict the response.
# Take the first line of the original tibble, repeat it 4 times
# then create new columns with different levels
newdata = heart_data %>% 
  slice(rep(1, 4)) %>%
  mutate(personality_2L     = c("B", "A", "A", "B"),
         sbp.2groups = c("Normal", "High", "Normal", "High"))


# Make rownames for easy identification. 
rownames(newdata) = c("B/Normal", "A/High", 
                      "A/Normal", "B/High")

# Run the models. 
## Note, we are using finalfit::glmmulti 
dependent   = "chd_8yr"
explanatory = c("personality_2L",
                "age",
                "height",
                "weight",
                "sbp.2groups",
                "chol",
                "smoking",
                "arcus")

fit8_chd = heart_data %>% 
  glmmulti(dependent, explanatory)

dependent   = "chd_8yr"
explanatory = c("personality_2L*sbp.2groups",
                "age",
                "height",
                "weight",
                #"sbp.2groups",
                "chol",
                "smoking",
                "arcus")

fit9_chd = heart_data %>%
  glmmulti(dependent, explanatory)

```

```{r}

## This code is complex but you can understand it if you work through. 

fit8_chd %>% 
  augment(newdata = newdata, type.predict = "link") %>%
  separate(.rownames, into = c("personality_2L", "sbp.2groups"), sep = "/") %>%
  mutate(
    personality_2L = factor(personality_2L, levels=c("B", "A"))) %>% 
  ggplot(aes(x = personality_2L, y=.fitted, group=sbp.2groups, colour=sbp.2groups))+
  geom_line()+
  ylab("Log-odds death") +
  ggtitle("Without interaction")

fit9_chd %>% 
  augment(newdata = newdata, type.predict = "link") %>%
  separate(.rownames, into = c("personality_2L", "sbp.2groups"), sep = "/") %>%
  mutate(
    personality_2L = factor(personality_2L, levels=c("B", "A"))) %>% 
  ggplot(aes(x = personality_2L, y=.fitted, group=sbp.2groups, colour=sbp.2groups))+
  geom_line()+
  ylab("Log-odds death") +
  ggtitle("With interaction")

```

*This interaction is not significant.*

# *Accounting for population stratification with random effects*

*We have noted previously that we should incorporate population stratification into models if available. This is important. If we have patients clustered by town, or hospital, or country, then this should be accounted for. Those patients are likely to have commonalities not captured else where in the data. If we wish the estimates for our other characteristics to be accurate, this is required.*

*Our models so far have included variables as `fixed effects`. We can go further and include something called `random effects`. This is useful when we have variables that we wish to account for, but not necessarily estimate directly, without losing power in the main analysis.*

*Turns out we actually have information on which hospitals the data was gathered from!*

```{r}
#| eval: false

load(here::here("patient_hospitals.rda"))

heart_data = heart_data %>% left_join(hospitals)

dependent   = "chd_8yr"
explanatory = c("personality_2L",
                "age",
                "height",
                "weight",
                "sbp.2groups",
                "chol",
                "smoking",
                "arcus")

fit10_chd = heart_data %>% 
  finalfit(dependent, explanatory,
           metrics = TRUE, random_effect = "hospital")

fit10     = fit10_chd[[1]]
met_fit10 = fit10_chd[[2]]

```

*To include a random effect, `finalfit` can't use `glm()` - it uses `glmer()` from `library(lme4)` instead.*

## *Answers*

### *1.*

```{r}
# Fit 4

dependent   = "chd_8yr"
explanatory = c("personality_2L","age", "height", "weight",
                #"sbp",
                "chol",
                "smoking",
                "arcus")

fit4_chd = heart_data %>% 
  finalfit(dependent, explanatory, metrics = TRUE)

fit4     = fit4_chd[[1]]
met_fit4  = fit4_chd[[2]]
rm(fit4_chd)
```
