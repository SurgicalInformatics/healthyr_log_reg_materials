---
title: "Introduction and data exploration"
author: "HealthyR+: Practical Logistic Regression, Session 1"
date: today
format:
  pdf: default
  html:
    code-fold: true
editor: visual
---

## What is Logistic Regression?

A regression analysis is a statistical process for estimating the relationships between variables. For instance, we may try to predict the blood pressure of a group of patients based on their age. As age and blood pressure are on a continuous scale, this is an example of linear regression.

Logistic regression is an extension of this, where the variable being predicted is categorical. We will deal with binary logistic regression, where the variable being predicted has two levels, e.g. yes or no, 0 or 1. In healthcare this is usually done for an event (like death) occurring or not occurring. Logistic regression can tell us the probability of the outcome occurring.

Logistic regression lets you adjust for the effects of confounding factors on an outcome. When you read a paper that says it has adjusted for confounding factors, this is the usual method which is used.

Adjusting for confounding factors allows us to isolate the true effect of a variable upon an outcome. For example, if we wanted to know the effects of smoking on deaths from heart attacks, we would need to also control for things like sex and diabetes, as we know they contribute towards heart attacks too.

![](age_bp.png)

Although in binary logistic regression the outcome must have two levels, the predictor variables (also known as the explanatory variables) can be either continuous or categorical.

Logistic regression can be performed to examine the influence of one predictor variable, which is known as a univariable analysis. Or multiple predictor variables, known as a multivariable analysis.

![](exam_pass.jpeg)

## Definitions

**Dependent** variable (in clinical research usually synonymous to **outcome**) - is what we are trying to explain, i.e. we are trying to identify the factors associated with a particular outcome. In binomial logistic regression, the dependent variable has exactly two levels (e.g. "Died" or "Alive", "Yes - Complications" or "No Complications", "Cured" or "Not Cured", etc.). Other types of logistic regression include 'ordinal', when the outcome variable has \>2 ordered levels, and 'multinomial', where the outcome variable has \>2 levels with no inherent order.

**Explanatory** variables (also known as **predictors**, **confounding** variables, or **"adjusted for"**) - patient-level information, usually including demographics (age, gender) as well as clinical information (disease stage, tumour type). Explanatory variables can be categorical as well as continuous, and categorical variables can have more than two levels.

**Univariable** - analysis with only one Explanatory variable.

**Multivariable** - analysis with more than one Explanatory variable. Synonymous to "adjusted".

(**Multivariate** - technically means more than one **Dependent variable** (we will not discuss this type of analysis), but very often used interchangeably with **Multivariable**.)

# Directed acyclic graph (DAG)

It is important to think about the causal pathway you are investigating, and identify any confounders and mediators.

![](dagitty-model-overview.png)

## Exercise 0

Let's make a DAG for our dataset: <https://www.dagitty.net/>

## Discussion

Why is one of the columns called univariable analysis when it clearly includes several explanatory variables?

![](globalsurg_logreg.png)

Source: Mortality of emergency abdominal surgery in high-, middle-, and low-income countries. GlobalSurg Collaborative (2016). British Journal of Surgery, 103(8), 971-988.

## Odds and probabilities

Odds and probabilities can get confusing so let's get them straight:

![](p_vs_odds2.png)

Odds and probabilities can always be interconverted. For example, if the odds of a patient dying from a disease are \`9 to 1\` then the probability of death (also known as risk) is 10%. Odds of \`1 to 1\` equal 50%.

$Odds = \frac{p}{1-p}$, where $p$ is the probability of the outcome occurring (or the circle being red).

Look at the numbers and convince yourself that this works.

## Odds ratios

For a given categorical explanatory variable (e.g. gender), the likelihood of an outcome/dependent occurring (e.g cancer) can be expressed in a ratio of odds or odds ratio , e.g. the odds of men developing cancer is 2-times that of females, odds ratio = 2.0.

![](or.png)

An alternative is a ratio of probabilities, called a risk ratio or relative risk. Odds ratios have useful mathematical characteristics and are the main expression of results in logistic regression analysis.

## Advanced: Logit function

An assumption of simple linear regression is that the residuals are normally distributed. A residual is the difference between an observation (y) and the prediction of that observation by the model. This doesn't mean that the dependent Y must be normally distributed, but it does have to be continuous, unbounded and measured on an interval or ratio scale.

Unfortunately, binary dependent variables fulfill none of these requirements.

In order to perform regression using a binary dependent variable, we are required to transform it into something more useful.

Rather than estimating $y$ = 0 or $y$ = 1 from the $x$-axis, we estimate the probability of $y$ = 1. Probabilities can only exist for values of 0 to 1. The probability scale is therefore not linear - straight lines do not make sense on it.

The odds scale runs from 0 to +∞. Probabilities from 0 to 0.5 are squashed into odds of 0 to 1, and probabilities from 0.5 to 1 have the expansive comfort of 1 to +∞.

This is why we fit binary data on a **log-odds scale.**

A log-odds scale sounds incredibly off-putting to non-mathematicians, but it is the perfect solution.

-   Log-odds run from −∞ to +∞;

-   odds of 1 become log-odds of 0;

-   a doubling and a halving of odds represent the same distance on the scale.

In this case we, we use a **logit transformation** to convert $y$ to **log-odds**. Log-odds are continuous, unbounded and measured on an interval, therefore work well for regression.

### Logit function

$\log_e (\frac{p}{1-p})$, where $p$ is the probability of the outcome occurring.

The logit function is the natural log of the odds that Y equals one of the categories.

Credit: <http://www.theanalysisfactor.com/what-is-logit-function/>

The fitted lines from a regression model of cardiovascular event by coffee consumption, stratified by smoking can be seen below on the log-odds scale (A) and the probability scale (B). Source: ["R for Health Data Science" by Harrison & Pius](https://argoshare.is.ed.ac.uk/healthyr_book/binary-logistic-regression.html).

![](2_prob_logodds.png)

Below we can see the logistic regression equation, the fitted lines on the probability scale, and the output from a standard base R analysis. The dots at the top and bottom of the plot represent individual patients who have had an event or not. The fitted line, therefore, represents the point-to-point probability of a patient with a particular set of characteristics having the event or not.

It is straightforward to convert these to odds ratios, a measure we can use to communicate effect size and direction effectively. To get the odds ratio, we taje the exponential of the coefficient on the log-odds scale.

For a continuous variable such as cups of coffee consumed, the odds ratio is the change in odds of a CV event associated with a 1 cup increase in coffee consumption. We are dealing with linear responses here, so the odds ratio is the same for an increase from 1 to 2 cups, or 3 to 4 cups etc. Remember that if the odds ratio for 1 unit of change is 1.5, then the odds ratio for 2 units of change is $exp(log(1.5)*2) = 2.25$

For a categorical variable such as smoking, the odds ratio is the change in odds of a CV event associated with smoking compared with not smoking (the reference level).

![](4_equation.png)

# Data preparation and exploration

## Load data and packages

3154 healthy young men aged 39-59 from the San Francisco area were assessed for their personality type. All were free from coronary heart disease at the start of the research. Eight and a half years later change in this situation was recorded. Primary outcome variable: coronary heart disease (Yes/No).

**Reference:**

Coronary Heart Disease in the Western Collaborative Group Study Final Follow-up Experience of 8 1/2 Years Ray H. Rosenman, MD; Richard J. Brand, PhD; C. David Jenkins, PhD; Meyer Friedman, MD; Reuben Straus, MD; Moses Wurm, MD JAMA. 1975;233(8):872-877. doi:[10.1001/jama.1975.03260080034016](10.1001/jama.1975.03260080034016).

```{r}
#| message: false
library(tidyverse)
library(finalfit)
library(knitr)
library(ggdag)

theme_set(theme_bw())
# Loading the wcgs dataset from the finalfit package:
heart_data = wcgs
```

For more information and examples see finalfit.org

N.B

`#|` precedes an executable option used in Quarto (= the new R Markdown). These are used for chunk settings. You will see them going forward in this Quarto document.

(In an R markdown document you would see the settings presented inside the curly brackets e.g. `{r, echo = FALSE}`).

## Data exploration and plotting

Below is a clever piece of code, especially `pivot_longer(cols = where(is.factor))`: we select all variables that are factors (=categorical) into the same column which then makes it easy to plot all with just one ggplot call and then put them on separate plots with `facet_wrap(~name)`. `geom_bar()` counts up rows of categorical data for us, so there is no need to use `count()` or `summarise()` beforehand.

```{r}
#| fig-width: 10
#| fig-height: 5

heart_data %>%
  pivot_longer(cols = where(is.factor)) %>%
  ggplot(aes(value)) +
  geom_bar(aes(fill = value), show.legend = FALSE) +
  facet_wrap(~name, scales = "free", ncol = 3) +
  coord_flip()
```

Continuous (numeric) data can be explored using a histogram: `geom_histogram()`:

```{r}
#| fig-width: 10
#| fig-height: 8


heart_data %>%
  pivot_longer(cols = where(is.numeric)) %>% 
  ggplot(aes(value)) +
  facet_wrap(~name, scales = "free", ncol = 3) +
  geom_histogram()
```

### Exercise 1

Create a plot of the `time` variable only, faceted by `chd`.

Hints:

-   copy the code from above

-   remove the `pivot_longer()` line - this is needed when plotting multiple variables at once

-   change the main variable - inside `ggplot(aes())` - from `value` to `timechd`

-   change the variable being faceted by from `name` to `chd`

-   add in `fig-height` and `fig-weight` as above

How would you plot time in years, not days? Hint: Divide the number of days by 365.

```{r}
#| message: false

# your R code here:



```

Discuss in pairs what this plot shows us.

## Derive new variables

```{r}
heart_data = heart_data %>%
  mutate(years = (timechd/365) %>% 
           ff_label("Time (years)"))

```

And now the tricky one: creating a binary 8-year CHD variable:

```{r}
#| fig-width: 5
#| fig-height: 3

# If the follow-up time is longer than 5 years, then the patient must have been alive at 5 years:
heart_data = heart_data %>%
  mutate(chd_8yr = if_else(years >= 8,
                            "No",
                            "CHD event or Censored"))

heart_data %>% 
  ggplot(aes(x = years, y = chd_8yr)) +
  geom_point()
```

If follow-up time is less that 8 years, need to check whether that's because they were diagnosed with CHD they or were lost to follow-up. So a single `if_else()` is not enough here - need to separate the CHD or Censored. We can do it using `case_when()`:

```{r}
#| fig-width: 4
#| fig-height: 3

# If follow-up time is less that 8 years, need to check whether that's because they were diagnosed with CHD they or were lost to follow-up:
heart_data = heart_data %>%
  mutate(chd_8yr = case_when(years >= 8 ~ "No" ,
                              years < 8 & chd == "Yes"  ~ "Yes",
                              years < 8 & chd == "No" ~ "Censored",
                              .default = "Other"
                            ))

heart_data %>% 
  ggplot(aes(x = years, y = chd_8yr)) +
  geom_point(alpha = 0.1)

```

There should be no patients classified as Other - as it would mean we've made a mistake in the conditions, or there's some missing data. The `.default = "Other"` can be supplied to `case_when()`, which is the value assigned when none of the our conditions match. So think of the last line like "Everything else", or "Everything that is left".

Because logistic regression wants a variable with two levels, we'll change the third level - "Censored" - to NA. This way only the two explicit levels - "Alive" or "Died" will be used. We will also make it into a factor and give it a label.

```{r}
heart_data = heart_data %>% 
  mutate(chd_8yr =  chd_8yr %>% 
           na_if("Censored") %>% 
           factor() %>% 
           ff_label("8-yr CHD"))

heart_data %>% 
  ggplot(aes(x = years, y = chd_8yr)) +
  geom_point(alpha = 0.1)

```

## Exercise 2

Create a new derived variable called `age.10` which is age divided by 10 (so a 65 year-old is 6.5). Hint: use mutate to create a new variable and divide age by 10.

```{r}
#| echo: false

# your R code here:


```

# What about logistic regression?

After the break, we will start exploring model modelling.

Here is a quick introduction our own `finalfit` package.

`finalfit` provides functions to perform univariable and multivariable logistic regression analyses, and to produce publication standard tables and odds ratio plots.

The function `summary_factorlist` produces table summarising a dependent variable by any number of explanatory variables. It requires, 1. a dataframe, 2. a dependent, 3. explanatory variables. There are options which can be seen in the Help tab (press F1 on `summary_factorlist`).

This is usually what is required for Table 1 in a paper. Explore here to see how it works:

```{r}
library(finalfit)

dependent = "personality_2L"
explanatory = c("age", "height", "weight",
                "sbp", "chol", "smoking", "arcus")

# note that since this is assigned to a variable, 
# it shows up in the Environment tab, but doesn't get printed
demographics_table = heart_data %>%
  summary_factorlist(dependent, explanatory,
                     p = TRUE, na_include = TRUE)
```

```{r}
demographics_table %>% 
  kable(align = c("l", "l", "r", "r", "r", "r"))
```

`finalfit` is also a function. This produces a `summary_factorlist` table, together with a univariable and multivariable logistic regression analysis. In the next session we will explore how to perform these analyses formally.

```{r}
dependent = "chd_8yr"
explanatory = c("personality_2L","age", "height", "weight",
                "sbp", "chol", "smoking", "arcus")

logreg_results = heart_data %>% 
  finalfit(dependent, explanatory)

```

```{r}
logreg_results %>% 
  kable(row.names = FALSE, align = c("l", "l", "r", "r", "r", "r"))
```

```{r}
#| fig-width: 10
#| fig-height: 5

heart_data %>% 
  or_plot(dependent, explanatory)
```

## Exercise 3

Remove messages and warnings from the output of the above code chunks.

## Answers

### 0.

```{}
dag {
"Blood pressure" [pos="-1.438,0.881"]
"Coronary heart disease" [outcome,pos="-1.150,0.983"]
"Personality type" [exposure,pos="-1.730,0.993"]
Age [adjusted,pos="-1.436,0.642"]
Cholesterol [pos="-1.266,0.736"]
Height [adjusted,pos="-1.436,0.700"]
Smoking [pos="-1.437,0.825"]
Weight [adjusted,pos="-1.436,0.740"]
"Blood pressure" -> "Coronary heart disease"
"Personality type" -> "Blood pressure"
"Personality type" -> "Coronary heart disease"
"Personality type" -> Smoking
Age -> "Coronary heart disease"
Age -> "Personality type"
Cholesterol -> "Coronary heart disease"
Height -> "Coronary heart disease"
Height -> "Personality type"
Smoking -> "Coronary heart disease"
Weight -> "Coronary heart disease"
Weight -> "Personality type"
}
```

### 1.

```{r}
# time against status 
heart_data %>% 
  ggplot(aes(timechd)) +
  facet_wrap(~chd) +
  geom_histogram()

# time unit in years
heart_data %>% 
  ggplot(aes(timechd/365)) +
  facet_wrap(~chd) +
  geom_histogram()
```

### 2.

```{r}
heart_data = heart_data %>% 
  mutate(age.10 = (age/10) %>% 
           ff_label("Age/10yr")) 
```

### 3.

```{}
#| warning: false
#| message: false
```
